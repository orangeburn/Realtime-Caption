#!/usr/bin/env python3
# download_model.py
# ğŸ”„ æ™ºèƒ½æ¨¡å‹ä¸‹è½½å’Œç‰ˆæœ¬ç®¡ç†è„šæœ¬
import os
import json
import hashlib
import asyncio
import threading
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from loguru import logger
from modelscope.hub.snapshot_download import snapshot_download
from modelscope.hub.api import HubApi
import requests

@dataclass
class ModelConfig:
    model_id: str
    revision: str = "master"
    cache_dir: Optional[str] = None
    description: str = ""

@dataclass 
class ModelVersion:
    model_id: str
    current_revision: str
    latest_revision: str
    local_path: str
    last_check: datetime
    last_update: Optional[datetime] = None
    file_hash: Optional[str] = None

class ModelDownloader:
    def __init__(self, config_file: str = "model_versions.json"):
        self.config_file = Path(config_file)
        self.hub_api = HubApi()

        BASE_DIR = Path(__file__).parent.parent.resolve()
        
        self.models_config = {
            "sensevoice_small": ModelConfig(
                model_id="iic/SenseVoiceSmall",
                revision="master",
                cache_dir=None,  # ä½¿ç”¨ ModelScope é»˜è®¤ç³»ç»Ÿç¼“å­˜
                description="SenseVoiceå°å‹ASRæ¨¡å‹"
            ),
            "fsmn_vad": ModelConfig(
                model_id="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch", 
                revision="v2.0.4",
                cache_dir=None,  # ä½¿ç”¨ ModelScope é»˜è®¤ç³»ç»Ÿç¼“å­˜
                description="FSMN VADæ¨¡å‹"
            ),
            "nllb200": ModelConfig(
                model_id="JustFrederik/nllb-200-distilled-600M-ct2-int8",
                revision="main", 
                cache_dir=None,  # ä½¿ç”¨ HuggingFace é»˜è®¤ç³»ç»Ÿç¼“å­˜
                description="NLLB distilled ç¿»è¯‘æ¨¡å‹ (CTranslate2æ ¼å¼)"
            )
        }
        
        logger.info("æ‰€æœ‰æ¨¡å‹å°†ä½¿ç”¨ç³»ç»Ÿçº§ç¼“å­˜ç›®å½•")
        
        # ä¸ºäº†å‘åå…¼å®¹ï¼Œæ£€æŸ¥æ—§è·¯å¾„æ˜¯å¦å­˜åœ¨
        self._check_existing_models()
        
        # åŠ è½½ç‰ˆæœ¬ä¿¡æ¯
        self.versions = self._load_versions()
    
    def _check_existing_models(self):
        """æ£€æŸ¥ç°æœ‰æ¨¡å‹è·¯å¾„ï¼Œæä¾›è¿ç§»æç¤º"""
        BASE_DIR = Path(__file__).parent.parent.resolve()
        
        # æ£€æŸ¥å½“å‰çš„æ—§è·¯å¾„
        old_paths = {
            "nllb200": BASE_DIR / "nllb200_ct2",
            "fsmn_vad": BASE_DIR / "model" / "vad"
        }
        
        existing_old_paths = []
        
        for model_name, old_path in old_paths.items():
            if old_path.exists():
                existing_old_paths.append({
                    "model": model_name,
                    "old_path": str(old_path)
                })
        
        if existing_old_paths:
            logger.info("ğŸ”„ æ£€æµ‹åˆ°é¡¹ç›®å†…çš„æ—§æ¨¡å‹è·¯å¾„:")
            for item in existing_old_paths:
                logger.info(f"  {item['model']}: {item['old_path']}")
            logger.info("ğŸ’¡ è¿™äº›æ¨¡å‹ä»å¯æ­£å¸¸ä½¿ç”¨ï¼Œæ–°ä¸‹è½½å°†ä½¿ç”¨ç³»ç»Ÿç¼“å­˜")
    
    def get_models_summary(self) -> dict:
        """è·å–æ‰€æœ‰æ¨¡å‹çš„ç»Ÿä¸€çŠ¶æ€æ‘˜è¦"""
        summary = {
            "cache_strategy": "system_cache",
            "description": "æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç³»ç»Ÿçº§ç¼“å­˜ç›®å½•",
            "models": {}
        }
        
        for name, config in self.models_config.items():
            version_info = self.versions.get(name)
            
            # æ£€æŸ¥æ—§è·¯å¾„
            BASE_DIR = Path(__file__).parent.parent.resolve()
            old_paths = {
                "nllb200": BASE_DIR / "nllb200_ct2",
                "fsmn_vad": BASE_DIR / "model" / "vad"
            }
            old_path = old_paths.get(name)
            
            model_info = {
                "model_id": config.model_id,
                "revision": config.revision,
                "description": config.description,
                "cache_strategy": "system_cache" if config.cache_dir is None else "custom_cache",
                "system_cache_path": None,
                "old_project_path": str(old_path) if old_path else None,
                "exists_old": old_path.exists() if old_path else False,
                "size_mb": None,
                "last_update": None
            }
            
            # è·å–ç³»ç»Ÿç¼“å­˜è·¯å¾„
            if version_info and version_info.local_path:
                model_info["system_cache_path"] = version_info.local_path
                
                cache_path = Path(version_info.local_path)
                if cache_path.exists():
                    try:
                        total_size = sum(f.stat().st_size for f in cache_path.rglob('*') if f.is_file())
                        model_info["size_mb"] = round(total_size / (1024 * 1024), 2)
                    except:
                        pass
            
            if version_info:
                model_info["last_update"] = version_info.last_update.isoformat() if version_info.last_update else None
                model_info["current_revision"] = version_info.current_revision
            
            summary["models"][name] = model_info
        
        return summary
        
    def _load_versions(self) -> Dict[str, ModelVersion]:
        """åŠ è½½ç‰ˆæœ¬ä¿¡æ¯"""
        if not self.config_file.exists():
            return {}
            
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                versions = {}
                for name, info in data.items():
                    info['last_check'] = datetime.fromisoformat(info['last_check'])
                    if info.get('last_update'):
                        info['last_update'] = datetime.fromisoformat(info['last_update'])
                    versions[name] = ModelVersion(**info)
                return versions
        except Exception as e:
            logger.warning(f"åŠ è½½ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def _save_versions(self):
        """ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯"""
        try:
            data = {}
            for name, version in self.versions.items():
                version_dict = asdict(version)
                version_dict['last_check'] = version.last_check.isoformat()
                if version.last_update:
                    version_dict['last_update'] = version.last_update.isoformat()
                data[name] = version_dict
                
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
    
    def _get_latest_revision(self, model_id: str, config: ModelConfig) -> Optional[str]:
        """è·å–æ¨¡å‹æœ€æ–°ç‰ˆæœ¬"""
        try:
            # å¯¹äºModelScopeæ¨¡å‹
            if "iic/" in model_id or "damo/" in model_id:
                # ä½¿ç”¨ModelScope APIè·å–æœ€æ–°ç‰ˆæœ¬
                model_info = self.hub_api.get_model(model_id)
                if model_info and 'revisions' in model_info:
                    revisions = model_info['revisions']
                    if revisions:
                        # è¿”å›æœ€æ–°çš„revision
                        return revisions[0]['revision']
            
            # å¯¹äºHuggingFaceæ¨¡å‹ï¼Œä½¿ç”¨ä¸åŒçš„API
            elif "/" in model_id and not ("iic/" in model_id or "damo/" in model_id):
                # HuggingFaceæ¨¡å‹ç›´æ¥è¿”å›é…ç½®ä¸­çš„revisionï¼ˆåˆ†æ”¯åï¼‰ï¼Œä¸ä½¿ç”¨SHA
                return config.revision
            
            logger.warning(f"æ— æ³•è·å–æ¨¡å‹ {model_id} çš„æœ€æ–°ç‰ˆæœ¬")
            return None
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ¨¡å‹ {model_id} æœ€æ–°ç‰ˆæœ¬å¤±è´¥: {e}")
            return None
    
    def _get_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except:
            return ""
    
    def check_model_updates(self, force_check: bool = False) -> List[str]:
        """æ£€æŸ¥æ¨¡å‹æ›´æ–°"""
        updated_models = []
        
        for name, config in self.models_config.items():
            try:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ£€æŸ¥æ›´æ–°ï¼ˆ24å°æ—¶æ£€æŸ¥ä¸€æ¬¡ï¼‰
                if not force_check and name in self.versions:
                    last_check = self.versions[name].last_check
                    if datetime.now() - last_check < timedelta(hours=24):
                        continue
                
                logger.info(f"æ£€æŸ¥æ¨¡å‹ {name} çš„æ›´æ–°...")
                
                # è·å–æœ€æ–°ç‰ˆæœ¬
                latest_revision = self._get_latest_revision(config.model_id, config)
                if not latest_revision:
                    continue
                
                # æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯
                if name not in self.versions:
                    self.versions[name] = ModelVersion(
                        model_id=config.model_id,
                        current_revision=config.revision,
                        latest_revision=latest_revision,
                        local_path="",
                        last_check=datetime.now()
                    )
                else:
                    self.versions[name].latest_revision = latest_revision
                    self.versions[name].last_check = datetime.now()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°
                current_rev = self.versions[name].current_revision
                if latest_revision != current_rev:
                    logger.info(f"å‘ç°æ¨¡å‹ {name} æœ‰æ–°ç‰ˆæœ¬: {current_rev} -> {latest_revision}")
                    updated_models.append(name)
                else:
                    logger.info(f"æ¨¡å‹ {name} å·²æ˜¯æœ€æ–°ç‰ˆæœ¬: {latest_revision}")
                    
            except Exception as e:
                logger.error(f"æ£€æŸ¥æ¨¡å‹ {name} æ›´æ–°å¤±è´¥: {e}")
        
        self._save_versions()
        return updated_models
    
    def download_model(self, model_name: str, background: bool = False) -> bool:
        """ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
        if model_name not in self.models_config:
            logger.error(f"æœªçŸ¥æ¨¡å‹: {model_name}")
            return False
        
        config = self.models_config[model_name]
        version_info = self.versions.get(model_name)
        
        # ç¡®å®šè¦ä¸‹è½½çš„ç‰ˆæœ¬
        revision = version_info.latest_revision if version_info else config.revision
        
        def _download():
            try:
                logger.info(f"å¼€å§‹ä¸‹è½½æ¨¡å‹ {model_name} (ç‰ˆæœ¬: {revision})")
                
                # æ ¹æ®æ¨¡å‹æ¥æºé€‰æ‹©ä¸‹è½½æ–¹å¼
                if "iic/" in config.model_id or "damo/" in config.model_id:
                    # ModelScopeæ¨¡å‹ä½¿ç”¨snapshot_download
                    local_path = snapshot_download(
                        model_id=config.model_id,
                        revision=revision,
                        cache_dir=config.cache_dir
                    )
                else:
                    # HuggingFaceæ¨¡å‹ä½¿ç”¨huggingface_hub
                    from huggingface_hub import snapshot_download as hf_snapshot_download
                    local_path = hf_snapshot_download(
                        repo_id=config.model_id,
                        revision=revision,
                        cache_dir=config.cache_dir
                    )
                
                # æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯
                if model_name not in self.versions:
                    self.versions[model_name] = ModelVersion(
                        model_id=config.model_id,
                        current_revision=revision,
                        latest_revision=revision,
                        local_path=local_path,
                        last_check=datetime.now(),
                        last_update=datetime.now()
                    )
                else:
                    self.versions[model_name].current_revision = revision
                    self.versions[model_name].local_path = local_path
                    self.versions[model_name].last_update = datetime.now()
                
                # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                try:
                    main_file = os.path.join(local_path, "pytorch_model.bin")
                    if os.path.exists(main_file):
                        self.versions[model_name].file_hash = self._get_file_hash(main_file)
                except:
                    pass
                
                self._save_versions()
                logger.info(f"æ¨¡å‹ {model_name} ä¸‹è½½å®Œæˆ: {local_path}")
                return True
                
            except Exception as e:
                logger.error(f"ä¸‹è½½æ¨¡å‹ {model_name} å¤±è´¥: {e}")
                return False
        
        if background:
            # åå°ä¸‹è½½
            thread = threading.Thread(target=_download, daemon=True)
            thread.start()
            logger.info(f"æ¨¡å‹ {model_name} åå°ä¸‹è½½å·²å¯åŠ¨")
            return True
        else:
            # å‰å°ä¸‹è½½
            return _download()
    
    def download_all_models(self, background: bool = False) -> bool:
        """ä¸‹è½½æ‰€æœ‰æ¨¡å‹"""
        success = True
        for model_name in self.models_config.keys():
            if not self.download_model(model_name, background=False):  # é€ä¸ªä¸‹è½½ä»¥é¿å…å¹¶å‘é—®é¢˜
                success = False
        return success
    
    def update_models_background(self) -> List[str]:
        """åå°æ£€æŸ¥å’Œæ›´æ–°æ¨¡å‹"""
        logger.info("å¼€å§‹åå°æ£€æŸ¥æ¨¡å‹æ›´æ–°...")
        
        # æ£€æŸ¥æ›´æ–°
        updated_models = self.check_model_updates()
        
        if updated_models:
            logger.info(f"å‘ç° {len(updated_models)} ä¸ªæ¨¡å‹æœ‰æ›´æ–°ï¼Œå¼€å§‹åå°ä¸‹è½½...")
            
            # åå°ä¸‹è½½æ›´æ–°çš„æ¨¡å‹
            for model_name in updated_models:
                self.download_model(model_name, background=True)
        else:
            logger.info("æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯æœ€æ–°ç‰ˆæœ¬")
        
        return updated_models
    
    def get_model_status(self) -> Dict[str, Dict]:
        status = {}
        for name, config in self.models_config.items():
            version_info = self.versions.get(name)
            status[name] = {
                "model_id": config.model_id,
                "description": config.description,
                "current_revision": version_info.current_revision if version_info else "æœªä¸‹è½½",
                "latest_revision": version_info.latest_revision if version_info else "æœªçŸ¥",
                "has_update": (version_info.latest_revision != version_info.current_revision) if version_info else False,
                "local_path": version_info.local_path if version_info else "",
                "last_check": version_info.last_check.isoformat() if version_info else "ä»æœªæ£€æŸ¥",
                "last_update": version_info.last_update.isoformat() if version_info and version_info.last_update else "ä»æœªæ›´æ–°"
            }
        return status


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æ¨¡å‹ä¸‹è½½å’Œæ›´æ–°å·¥å…·")
    parser.add_argument("--check", action="store_true", help="æ£€æŸ¥æ¨¡å‹æ›´æ–°")
    parser.add_argument("--download", type=str, help="ä¸‹è½½æŒ‡å®šæ¨¡å‹")
    parser.add_argument("--download-all", action="store_true", help="ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
    parser.add_argument("--background-update", action="store_true", help="åå°æ£€æŸ¥å’Œæ›´æ–°æ¨¡å‹")
    parser.add_argument("--status", action="store_true", help="æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶æ£€æŸ¥æ›´æ–°")
    
    args = parser.parse_args()
    
    downloader = ModelDownloader()
    
    if args.status:
        # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        status = downloader.get_model_status()
        print("\n=== æ¨¡å‹çŠ¶æ€ ===")
        for name, info in status.items():
            print(f"\nğŸ“¦ {name}:")
            print(f"  ID: {info['model_id']}")
            print(f"  æè¿°: {info['description']}")
            print(f"  å½“å‰ç‰ˆæœ¬: {info['current_revision']}")
            print(f"  æœ€æ–°ç‰ˆæœ¬: {info['latest_revision']}")
            print(f"  æœ‰æ›´æ–°: {'æ˜¯' if info['has_update'] else 'å¦'}")
            print(f"  æœ¬åœ°è·¯å¾„: {info['local_path']}")
            print(f"  æœ€åæ£€æŸ¥: {info['last_check']}")
            print(f"  æœ€åæ›´æ–°: {info['last_update']}")
    
    elif args.check:
        # æ£€æŸ¥æ›´æ–°
        updated_models = downloader.check_model_updates(force_check=args.force)
        if updated_models:
            print(f"å‘ç° {len(updated_models)} ä¸ªæ¨¡å‹æœ‰æ›´æ–°: {', '.join(updated_models)}")
        else:
            print("æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯æœ€æ–°ç‰ˆæœ¬")
    
    elif args.download:
        # ä¸‹è½½æŒ‡å®šæ¨¡å‹
        success = downloader.download_model(args.download)
        if success:
            print(f"æ¨¡å‹ {args.download} ä¸‹è½½æˆåŠŸ")
        else:
            print(f"æ¨¡å‹ {args.download} ä¸‹è½½å¤±è´¥")
    
    elif args.download_all:
        # ä¸‹è½½æ‰€æœ‰æ¨¡å‹
        success = downloader.download_all_models()
        if success:
            print("æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆ")
        else:
            print("éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥")
    
    elif args.background_update:
        # åå°æ›´æ–°
        updated_models = downloader.update_models_background()
        if updated_models:
            print(f"å·²å¯åŠ¨ {len(updated_models)} ä¸ªæ¨¡å‹çš„åå°æ›´æ–°")
        else:
            print("æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œæ— éœ€æ›´æ–°")
    
    else:
        # é»˜è®¤è¡Œä¸ºï¼šæ£€æŸ¥æ›´æ–°å¹¶ä¸‹è½½
        parser.print_help()

if __name__ == "__main__":
    main()
