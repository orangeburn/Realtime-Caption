#!/usr/bin/env python3
"""
åç«¯å¯åŠ¨æ£€æµ‹è„šæœ¬
è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶ç¯å¢ƒå¹¶å¯åŠ¨åç«¯æœåŠ¡
"""

import os
import sys
import subprocess
import importlib.util

def check_gpu_availability():
    """æ£€æµ‹GPUå¯ç”¨æ€§"""
    print("ğŸ” æ£€æµ‹ç¡¬ä»¶ç¯å¢ƒ...")
    
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            print(f"âœ… æ£€æµ‹åˆ°GPU: {gpu_name} (å…±{gpu_count}ä¸ªè®¾å¤‡)")
            return True, gpu_name
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°CUDA GPU")
            return False, None
    except ImportError:
        print("âš ï¸ PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ£€æµ‹GPU")
        return False, None
    except Exception as e:
        print(f"âŒ GPUæ£€æµ‹å¤±è´¥: {e}")
        return False, None

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    print("\nğŸ“‹ æ£€æŸ¥ä¾èµ–åŒ…...")
    
    required_packages = [
        ("torch", "PyTorch"),
        ("ctranslate2", "CTranslate2"),
        ("sentencepiece", "SentencePiece"),
        ("funasr", "FunASR"),
        ("fastapi", "FastAPI"),
        ("websockets", "WebSockets"),
        ("uvicorn", "Uvicorn"),
        ("loguru", "Loguru")
    ]
    
    missing_packages = []
    
    for package, display_name in required_packages:
        if importlib.util.find_spec(package) is None:
            print(f"âŒ {display_name} æœªå®‰è£…")
            missing_packages.append(package)
        else:
            print(f"âœ… {display_name} å·²å®‰è£…")
    
    if missing_packages:
        print(f"\nğŸ’¡ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print(f"pip install {' '.join(missing_packages)}")
        return False
    
    return True

def estimate_memory_usage(has_gpu):
    """ä¼°ç®—å†…å­˜ä½¿ç”¨é‡"""
    print("\nğŸ’¾ å†…å­˜éœ€æ±‚è¯„ä¼°...")
    
    if has_gpu:
        print("ğŸ¯ GPUæ¨¡å¼:")
        print("  - ASRæ¨¡å‹ (GPU): ~2-4GB æ˜¾å­˜")
        print("  - VADæ¨¡å‹ (CPU): ~500MB å†…å­˜")
        print("  - ç¿»è¯‘æ¨¡å‹ (CPU): ~1-2GB å†…å­˜")
        print("  - æ€»è®¡: ~2GBå†…å­˜ + 2-4GBæ˜¾å­˜")
    else:
        print("ğŸ¯ CPUæ¨¡å¼:")
        print("  - ASRæ¨¡å‹ (CPU): ~2-4GB å†…å­˜")
        print("  - VADæ¨¡å‹ (CPU): ~500MB å†…å­˜") 
        print("  - ç¿»è¯‘æ¨¡å‹ (CPU): ~1-2GB å†…å­˜")
        print("  - æ€»è®¡: ~4-7GB å†…å­˜")
    
    return True

def show_performance_tips(has_gpu):
    """æ˜¾ç¤ºæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
    print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    
    if has_gpu:
        print("âœ… GPUåŠ é€Ÿå·²å¯ç”¨ï¼Œæ€§èƒ½æœ€ä½³")
        print("  - ASRè¯†åˆ«: å®æ—¶å¤„ç†ï¼Œä½å»¶è¿Ÿ")
        print("  - å»ºè®®: ç¡®ä¿GPUé©±åŠ¨æœ€æ–°")
    else:
        print("âš ï¸ ä»…CPUæ¨¡å¼ï¼Œæ€§èƒ½ä¼šæœ‰æ‰€é™ä½")
        print("  - ASRè¯†åˆ«: å¯èƒ½æœ‰è½»å¾®å»¶è¿Ÿ")
        print("  - å»ºè®®: ä½¿ç”¨å¤šæ ¸CPUï¼Œå…³é—­ä¸å¿…è¦ç¨‹åº")
        print("  - å¤‡é€‰: è€ƒè™‘ä½¿ç”¨äº‘GPUæœåŠ¡")

def start_backend_server(port=27000):
    """å¯åŠ¨åç«¯æœåŠ¡å™¨"""
    print(f"\nğŸš€ å¯åŠ¨åç«¯æœåŠ¡å™¨ (ç«¯å£: {port})...")
    
    try:
        # æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
        import socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        result = sock.connect_ex(('127.0.0.1', port))
        sock.close()
        
        if result == 0:
            print(f"âš ï¸ ç«¯å£ {port} å·²è¢«å ç”¨")
            print("è¯·æ£€æŸ¥æ˜¯å¦å·²æœ‰åç«¯æœåŠ¡åœ¨è¿è¡Œ")
            return False
        
        # å¯åŠ¨æœåŠ¡å™¨
        script_dir = os.path.dirname(os.path.abspath(__file__))
        server_script = os.path.join(script_dir, "../a4s/server_wss_split.py")
        
        if not os.path.exists(server_script):
            print(f"âŒ æ‰¾ä¸åˆ°æœåŠ¡å™¨è„šæœ¬: {server_script}")
            return False
        
        print("âœ… å¯åŠ¨ä¸­...")
        subprocess.run([
            sys.executable, server_script, "--port", str(port)
        ])
        
    except KeyboardInterrupt:
        print("\nğŸš¦ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨åœæ­¢...")
        return True
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸµ å®æ—¶å­—å¹•åç«¯å¯åŠ¨æ£€æµ‹")
    print("=" * 50)
    
    # æ£€æŸ¥GPU
    has_gpu, gpu_name = check_gpu_availability()
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        print("\nâŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·å®‰è£…ç¼ºå°‘çš„åŒ…åé‡è¯•")
        sys.exit(1)
    
    # å†…å­˜è¯„ä¼°
    estimate_memory_usage(has_gpu)
    
    # æ€§èƒ½å»ºè®®
    show_performance_tips(has_gpu)
    
    # è¯¢é—®æ˜¯å¦å¯åŠ¨
    print("\n" + "="*50)
    choice = input("æ˜¯å¦ç°åœ¨å¯åŠ¨åç«¯æœåŠ¡ï¼Ÿ(y/n): ").lower().strip()
    
    if choice in ['y', 'yes', 'æ˜¯']:
        port = 27000
        port_input = input(f"ç«¯å£å· (é»˜è®¤ {port}): ").strip()
        if port_input:
            try:
                port = int(port_input)
            except ValueError:
                print("âš ï¸ ç«¯å£å·æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤ç«¯å£")
        
        success = start_backend_server(port)
        
        if success:
            print("\nâœ… åç«¯æœåŠ¡å·²åœæ­¢")
        else:
            print("\nâŒ åç«¯æœåŠ¡å¯åŠ¨å¤±è´¥")
            sys.exit(1)
    else:
        print("\nğŸ‘‹ å·²å–æ¶ˆå¯åŠ¨")

if __name__ == "__main__":
    main()